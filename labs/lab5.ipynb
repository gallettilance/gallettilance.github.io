{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5: KNN Regression\n",
        "----------------------------------\n",
        "\n",
        "**Goals**:\n",
        " - Practice KNN regression in preparation for this week's homework.\n",
        " - Practice using cross-validation to find the optimal hyperparameter (useful for competitions).\n",
        "\n",
        " For this lab, we will use the archived Kaggle Flood Prediction competition here:\n",
        "\n",
        "https://www.kaggle.com/competitions/playground-series-s4e5\n",
        "\n",
        " Please join this competition, download the `train.csv` and `test.csv` files, and place them in the same folder as this notebook."
      ],
      "metadata": {
        "id": "W2yr0ILjZJ5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "First, we need to standardize the features. Please fill in the code marked `TODO`."
      ],
      "metadata": {
        "id": "8Q2A-tAvdJme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mp4zE11qMUcu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load train and test CSV files\n",
        "# We'll only fit the model to the first 10,000 samples of the training data to save time.\n",
        "train_data = pd.read_csv('train.csv')[:10000]\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Drop id column from the training dataset\n",
        "train_data = train_data.drop(['id'], axis=1)\n",
        "\n",
        "# Separate features (X) and target (y) from training data\n",
        "X_train = train_data.drop('FloodProbability', axis=1)\n",
        "y_train = train_data['FloodProbability']\n",
        "\n",
        "# Create a Pipeline object with StandardScaler and KNeighborsRegressor\n",
        "# model = TODO\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation\n",
        "\n",
        "Now, we want to determine the cross validation accuracy for varying values of `k`.\n",
        "\n",
        "Complete the following code to plot the average validation R^2 vs. `k` and the average evaluation time per sample vs. `k`."
      ],
      "metadata": {
        "id": "ymJg3kCCC7Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter range for n_neighbors\n",
        "n_neighbors_values = range(1, 21)  # Testing for neighbors from 1 to 20\n",
        "\n",
        "# Store results\n",
        "n_neighbors_list = []\n",
        "r2_scores = []\n",
        "times_per_sample = []\n",
        "\n",
        "# Perform cross-validation over different values of n_neighbors\n",
        "for n_neighbors in n_neighbors_values:\n",
        "    # Create a Pipeline object with StandardScaler and KNeighborsRegressor\n",
        "    # model = TODO\n",
        "\n",
        "    # Measure the time taken for cross-validation\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform cross-validation and calculate mean validation accuracy\n",
        "    # Perform 5-fold cross-validation using the cross_val_score function\n",
        "    #\n",
        "    # mean_validation_score = TODO\n",
        "\n",
        "    # Calculate elapsed time and seconds per sample\n",
        "    elapsed_time = time.time() - start_time\n",
        "    seconds_per_sample = elapsed_time / len(X_train)\n",
        "\n",
        "    # Store results for plotting\n",
        "    n_neighbors_list.append(n_neighbors)\n",
        "    r2_scores.append(mean_validation_score)\n",
        "    times_per_sample.append(seconds_per_sample)\n",
        "\n",
        "    # Print out the validation accuracy, the value of n_neighbors, and the time per sample\n",
        "    print(f'Validation Accuracy: {mean_validation_score:.4f} with n_neighbors={n_neighbors}')\n",
        "    print(f'Time taken: {elapsed_time:.2f} seconds, Seconds per sample: {seconds_per_sample:.6f} seconds')\n",
        "\n",
        "# Plotting results\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Left plot: R² score vs number of neighbors\n",
        "axs[0].plot(n_neighbors_list, r2_scores, marker='o', linestyle='-', color='b')\n",
        "axs[0].set_xlabel('Number of Neighbors')\n",
        "axs[0].set_ylabel('Validation R² Score')\n",
        "axs[0].set_title('Validation R² Score vs. Number of Neighbors')\n",
        "\n",
        "# Right plot: Time per sample vs R² score\n",
        "axs[1].plot(n_neighbors_list, times_per_sample, color='r')\n",
        "axs[1].set_xlabel('Number of Neighbors')\n",
        "axs[1].set_ylabel('Time per Sample (seconds)')\n",
        "axs[1].set_title('Time per Sample vs. Number of Neighbors')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Output the best hyperparameter\n",
        "best_n_neighbors = n_neighbors_list[np.argmax(r2_scores)]\n",
        "best_score = np.max(r2_scores)\n",
        "print(f'Best n_neighbors: {best_n_neighbors} with Validation Accuracy: {best_score:.4f}')\n"
      ],
      "metadata": {
        "id": "tvlaCpwnOrt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit to Kaggle\n",
        "\n",
        "Using the optimal `k` you found, complete the following code to generate predictions on the test data.\n",
        "\n",
        "Then, submit the `submission.csv` to Kaggle. Please show the TA both the plots generated above and the Kaggle submission result."
      ],
      "metadata": {
        "id": "N1dW4OLVGO32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model using the optimal k value\n",
        "# model = TODO\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# For the test data, we also drop unnecessary columns but keep 'id' for the final submission\n",
        "X_test = test_data.drop(['id'], axis=1)\n",
        "test_ids = test_data['id']\n",
        "\n",
        "# Make prediction on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission = pd.DataFrame({'id': test_ids, 'FloodProbability': y_pred})\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' has been created!\")"
      ],
      "metadata": {
        "id": "Tp4_OU2UhIeB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}