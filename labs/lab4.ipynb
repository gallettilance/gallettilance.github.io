{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e534f5e3",
   "metadata": {},
   "source": [
    "# **Lab 4: Topic Modeling with Latent Semantic Analysis (LSA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "%pip install nltk scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0457d",
   "metadata": {},
   "source": [
    "\n",
    "### **Part 1: Loading and Preprocessing the BBC News Dataset**\n",
    "\n",
    "In this section, weâ€™ll load the dataset, preprocess the text by removing stopwords, tokenizing, and creating a term-document matrix using TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42990ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Load the BBC news dataset\n",
    "data = ...\n",
    "\n",
    "# Check the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ea5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# A simple function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    return ' '.join([word.lower() for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "# TODO: Apply the preprocessing function to the 'content' column\n",
    "data['processed_content'] = ...\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.05, max_features=1000, ngram_range=(1, 2))\n",
    "\n",
    "# TODO: Create the term-document matrix\n",
    "term_doc_matrix = ...\n",
    "\n",
    "# Get the terms (feature names) from the vectorizer\n",
    "terms = ...\n",
    "\n",
    "# Display the shape of the term-document matrix\n",
    "print(f\"Term-Document Matrix Shape: {term_doc_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6e807",
   "metadata": {},
   "source": [
    "\n",
    "### **Part 2: Applying SVD to the Term-Document Matrix**\n",
    "\n",
    "In this section, we will apply **Singular Value Decomposition (SVD)** to reduce the term-document matrix into its latent structure and identify the topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5345c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# TODO: Define the number of components\n",
    "num_components = ...\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=num_components)\n",
    "\n",
    "# TODO: Fit the SVD model\n",
    "svd_matrix = svd_model.fit_transform(...)\n",
    "\n",
    "# Show the resulting latent space (topic space)\n",
    "print(f\"Latent Topic Matrix Shape: {svd_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the top terms for each topic\n",
    "\n",
    "num_top_words = ... # TODO: Adjust this until you can easily identify the topics\n",
    "\n",
    "for i, topic in enumerate(svd_model.components_):\n",
    "    top_term_indices = ... # TODO: Get the indices of the top terms\n",
    "    top_terms = [terms[i] for i in top_term_indices]\n",
    "    print(f\"Topic {i+1}: {', '.join(top_terms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b641c7",
   "metadata": {},
   "source": [
    "\n",
    "### **Part 3: Labeling the Topics**\n",
    "\n",
    "TODO: Using the terms extracted from each topic, try to assign labels that best describe what each topic is about.\n",
    "\n",
    "- **Topic 1**: ...\n",
    "- **Topic 2**: ...\n",
    "- **Topic 3**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284765ec",
   "metadata": {},
   "source": [
    "\n",
    "### **Summary & Takeaways**\n",
    "\n",
    "In this lab, you have:\n",
    "1. Preprocessed the BBC News dataset and created a term-document matrix using TF-IDF.\n",
    "2. Applied SVD to reduce the term-document matrix into a lower-dimensional space, revealing hidden topics.\n",
    "3. Examined the most significant terms in each topic and interpreted their meaning.\n",
    "4. Labeled the topics based on the terms and document clusters.\n",
    "\n",
    "You now have a better understanding of how **LSA** can reveal hidden topics in a collection of text documents and how similar documents can group together based on their content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
